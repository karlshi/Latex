
%% overclocking_tcad.tex
%% by Kan Shi


%\usepackage{times,epsfig,amsfonts,bm}
%\usepackage{pdflscape}
%\usepackage{afterpage}
%\usepackage{algorithm}
%\usepackage{algorithmic}
%\usepackage{fmtcount,threeparttable, setspace, nicefrac}
%\usepackage[dvips]{color}
%\usepackage{amsthm}

\documentclass[journal]{IEEEtran}
\usepackage{cite}

\ifCLASSINFOpdf
  \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  \graphicspath{{../Figures/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  \DeclareGraphicsExtensions{.eps}
\fi
\usepackage{epstopdf}


\usepackage{multirow}
\usepackage{amssymb}
\usepackage[cmex10]{amsmath}
%\usepackage{algorithmic}
%\usepackage{array}
\usepackage[tight,footnotesize]{subfigure}
\usepackage{stfloats}
\usepackage{threeparttable}



\begin{document}

\title{Imprecise Computing in Datapath Design: Precision Loss or Timing Violations}
%Imprecise Datapath Design: An Overclocking Approach
%Imprecise Computation Through Overclocking

\author{Kan~Shi,
        David~Boland,~\IEEEmembership{Member,~IEEE,}
        and~George~A.~Constantinides,~\IEEEmembership{Senior~Member,~IEEE}% <-this % stops a space
	\thanks{K. Shi, D. Boland and G. A. Constantinides are with the Department of Electrical and Electronic Engineering, Imperial College London, London, SW7 2BT, U.K. (email: \{k.shi11, david.boland03, g.constantinides\}@imperial.ac.uk)}%
	%\thanks{M. Shell is with the Department of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta,GA, 30332 USA e-mail: (see http://www.michaelshell.org/contact.html).}% <-this % stops a space
%\thanks{J. Doe and J. Doe are with Anonymous University.}% <-this % stops a space
\thanks{Manuscript received April 19, 2005; revised December 27, 2012.}}

% note the % following the last \IEEEmembership and also \thanks -
% these prevent an unwanted space from occurring between the last author name
% and the end of the author line. i.e., if you had this:
%
% \author{....lastname \thanks{...} \thanks{...} }
%                     ^------------^------------^----Do not want these spaces!
%
% a space would be appended to the last name and could cause every name on that
% line to be shifted left slightly. This is one of those "LaTeX things". For
% instance, "\textbf{A} \textbf{B}" will typeset as "A B" not "AB". To get
% "AB" then you have to do: "\textbf{A}\textbf{B}"
% \thanks is no different in this regard, so shield the last } of each \thanks
% that ends a line with a % and do not let a space in before the next \thanks.
% Spaces after \IEEEmembership other than the last one are OK (and needed) as
% you are supposed to have spaces between the names. For what it is worth,
% this is a minor point as most people would not even notice if the said evil
% space somehow managed to creep in.



% The paper headers
\markboth{Journal of \LaTeX\ Class Files,~Vol.~11, No.~4, December~2012}%
{Shell \MakeLowercase{\textit{et al.}}: Bare Demo of IEEEtran.cls for Journals}

\maketitle

% As a general rule, do not put math, special symbols or citations
% in the abstract or keywords.
\begin{abstract}
The abstract.
\end{abstract}

\begin{IEEEkeywords}

\end{IEEEkeywords}


% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle



\section{Introduction}
% The very first letter is a 2 line initial drop letter followed
% by the rest of the first word in caps.
%
% form to use if the first word consists of a single letter:
% \IEEEPARstart{A}{demo} file is ....
%
% form to use if you need the single drop letter followed by
% normal text (unknown if ever used by IEEE):
% \IEEEPARstart{A}{}demo file is ....
%
% Some journals put the first two words in caps:
% \IEEEPARstart{T}{his demo} file is ....
%
% Here we have the typical use of a "T" for an initial drop letter
% and "HIS" in caps to complete the first word.
\IEEEPARstart{T}{his} demo file is intended to serve as a ``starter file''
for IEEE journal papers produced under \LaTeX\ using
IEEEtran.cls version 1.8 and later.
% You must have at least 2 lines in the paragraph with the drop letter
% (should never be an issue)
I wish you the best of success.

\hfill mds

\hfill December 27, 2012

\subsection{Subsection Heading Here}
Subsection text here.


\subsubsection{Subsubsection Heading Here}
Subsubsection text here.
\section{Ripple Carry Adder}\label{section_RCA}
\subsection{Adder Structures in FPGAs}
%something about fast carry logic in FPGA and pictures
Adders serve as a key building block for arithmetic operations. Generally speaking, the ripple carry adder (RCA) is the most straightforward and widely used adder structure. As such, the philosophy of our approach is first exemplified with the analysis of a RCA. We later describe how this methodology can be extended to other arithmetic operators in Section~\ref{section_CCM} by discussing  the CCM that is commonly used in DSP applications and numerical algorithms.

Typically the maximum frequency of a RCA is determined by the longest carry propagation. Consequently, modern FPGAs offer built-in architectures for very fast ripple carry addition. For instance, the Altera Cyclone series uses fast tables~\cite{AlteraCyclone} while the Xilinx Virtex series employs dedicated multiplexers and encoders for the fast carry logic~\cite{Virtex6}. Figure~\ref{FPGA adder} illustrates the structure of an $n$-bit RCA, which is composed of $n$ serial-connected full adders (FAs) and utilizes the internal fast carry logic of the Virtex-6 FPGA.

While the fast carry logic reduces the time of each individual carry-propagation delay, the overall delay of carry-propagation will eventually overwhelm the delay of sum generation of each LUT with increasing operand word-lengths. For our initial analysis, we assume that the carry propagation delay of each FA is a constant value $\mu$, which is a combination of logic delay and routing delay, and hence the critical path delay of the RCA is $\mu_{RCA}=n\mu$, as shown in~Figure~\ref{FPGA adder}. For an $n$-bit RCA, it follows that if the sampling period $T_S$ is greater than $\mu_{RCA}$, correct results will be sampled. If, however, $T_S<\mu_{RCA}$, intermediate results will be sampled, potentially generating errors.
%
\begin{figure}[t]
  \centering
  \includegraphics[width=3in]{./Figures/FastCarryLogic3.eps}
%  \vspace{-2ex}
  \caption{An $n$-bit ripple carry adder in Virtex-6 FPGA.}
  \label{FPGA adder}
  %\vspace{-3.5ex}
\end{figure}

In the following sections, we consider two methods that would allow the circuit to run at a frequency higher than $1/{T_S}$. The first is a traditional circuit design approach where operations occur without timing violations. To this end, the operand word-length is truncated in order to meet the timing requirement. This process results in truncation or roundoff error. In our proposed new scenario, circuits are implemented with greater word-length, but are clocked beyond the safe region so that timing violations sometimes occur. This process generates ``overclocking error''.

 %We note that it may be possible to operate at a higher clock frequency than $1/T_{S}$ by using alternative adder structures, such as carry-select adder and carry lookahead adder. However, the effectiveness of these techniques is limited in FPGAs due to the build-in structures for the acceleration of carry propagation. In addition, such techniques will require substantial extra silicon area.

\subsection{Probabilistic Model of Truncation Error}\label{section_RCA_TruncationError}
For ease of discussion, we assume that the input to our circuit is a fixed point number scaled to lie in the range $[-1,1)$. For our initial analysis, we assume every bit of each input is uniformly and independently generated. However, this assumption will be relaxed in Section~\ref{Section_Experiments} where the predictions are verified using real image data. The errors at the output are evaluated in terms of the absolute value and the probability of their occurring. These two metrics are combined as the error expectation.

If the input signal of a circuit is $k$ bits, truncation error occurs when the input signal is truncated from $k$ bits to $n$ bits. Under this premise, the mean value of the truncated bits at signal input ($E_{Tin}$) is given by (\ref{ET at single input}).
%
%\vspace{-1ex}
\begin{eqnarray}\label{ET at single input}
%\small
%\footnotesize
%\scriptsize
  \begin{split}
    E_{Tin} &= \frac{1}{2}\sum_{i=n+1}^{k}2^{-i}\\
    &= 2^{-n-1}-2^{-k-1}
%  \vspace{-1ex}
  \end{split}
\end{eqnarray}
%\normalsize

Since we assume there are two mutually independent inputs to the RCA, the overall expectation of truncation error for the RCA is given by (\ref{TruncationError}).
%
%\vspace{-1ex}
\begin{eqnarray}\label{TruncationError}
%\small
%\footnotesize
  E_T=\left\{
    \begin{matrix}
        2^{-n}-2^{-k}, & \textrm{if $n<k$}\\
        0, & \textrm{otherwise}
    \end{matrix}
  \right.
\end{eqnarray}
%\normalsize

\subsection{Probabilistic Model of Overclocking Error}
\subsubsection{Generation of Overclocking Error}\label{subsub:Generation of Overclocking Error}
For a given $T_S$, the maximum length of error-free carry propagation is described by~(\ref{Max.length of carry chain}), where $f_S$ denotes the sampling frequency.
%
%\vspace{-1ex}
\begin{eqnarray}\label{Max.length of carry chain}
%\small
%\footnotesize
%\scriptsize
    b := \left\lceil \frac{T_S}{\mu} \right\rceil= \left\lceil \frac{1}{\mu\cdot f_S}\right\rceil
\end{eqnarray}
%\normalsize

However, since the length of an actual carry chain during execution is dependent upon input patterns, in general, the worst case may occur rarely. To determine when this timing constraint is not met and the size of the error in this case, we expand standard results~\cite{DigitalICDesign} to the following statements, which examine carry generation, propagation and annihilation, as well as the corresponding summation results of a single bit $i$, according to the relationship between its input patterns $A_i$ and $B_i$:
%
 \begin{itemize}
   \item If $\!A_i\!=\!B_i\!=1$, a new carry chain is generated at bit $i$, and $S_i\!=\!C_{i-1}$;
   \item If $A_i\neq B_i$, the carry propagates for this carry chain at bit $i$, and $S_i\!=\!0$;
   \item If $\!A_i\!=\!B_i$, the current carry chain annihilates at bit $i$, and $S_i\!\!=\!\!1$.
 \end{itemize}

\subsubsection{Absolute Value of Overclocking Error}
For an $n$-bit RCA, let $C_{tm}$ denote the carry chain generated at bit $S_t$ with the length of $m$ bits. For a certain $f_S$, the maximum length of error-free carry propagation, $b$, is determined through (\ref{Max.length of carry chain}). The presence of overclocking error requires $m>b$. Since the length of carry chain cannot be greater than $n$, parameters $t$ and $m$ are bounded by (\ref{t_RCA}) and (\ref{m_RCA}):
%
%\vspace{-1ex}
\begin{align}
%\small
%\footnotesize
%\scriptsize
  \label{t_RCA}  0&\leq t \leq n-b\\
    b&<m\leq n+1-t      \label{m_RCA}
%    \vspace{-1ex}
\end{align}
%\normalsize

For $C_{tm}$, correct results will be generated from bit $S_t$ to bit $S_{t+b-1}$. Hence the absolute value of error seen at the output, normalized to the MSB ($2^n$), is given by (\ref{Output Error}), where $\hat{S_i}$ and $S_i$ denote the actual and error-free output of bit $i$ respectively.
%
%\vspace{-1ex}
\begin{eqnarray}\label{Output Error}
%\small
%\footnotesize
    e_{tm}=\frac{\left|\sum_{i=t+b}^{n}(S_i-\hat{S_i})\cdot 2^i\right|}{2^n}
%    \vspace{-1ex}
\end{eqnarray}
%\normalsize

$S_i$ and $\hat{S_i}$ can be determined using the equations from the previous statements in Section~\ref{subsub:Generation of Overclocking Error}. In the error-free case, the carry will propagate from bit $S_t$ to bit $S_{t+m-1}$, and we will obtain $S_{t+b}=S_{t+b+1}=\cdots=S_{t+m-2}=0$ for carry propagation, and $S_{t+m-1}=1$ for carry annihilation. However, when a timing violation occurs, the carry will not propagate through all these bits. Substituting these values into (\ref{Output Error}) yields (\ref{etm}). Interestingly, the value of overclocking error has no dependence on the length of carry chain $m$.
%
%Instead, $\hat{S}_{t+b}=\hat{S}_{t+b+1}=\cdots=\hat{S}_{t+m-2}=1$ and $\hat{S}_{t+m-1}=0$. It is worth noting that these expressions are obtained based on the assumption that all the internal bits are initialized to zero.
%
\begin{eqnarray}\label{etm}
%\small
%\footnotesize
  \begin{split}
    e_{tm} &= \frac{\left|2^{t+m-1}-2^{t+m-2}-\dots-2^{t+b}\right|}{2^n}\\
    &= 2^{t+b-n}
  \end{split}
\end{eqnarray}
%\normalsize

\subsubsection{Probability of Overclocking Error}
The carry chain $C_{tm}$ occurs when there is a carry generated at bit $t$, a carry annihilated at bit $t+m-1$ and the carry propagates in between. Consequently, its probability $P_{tm}$ is given by (\ref{Ptm_RCA}).
%
%\vspace{-1ex}
\begin{eqnarray}\label{Ptm_RCA}
%\small
%\footnotesize
  P_{tm}=P_{(A_t=B_t=1)}P_{(A_{t+m-1}=B_{t+m-1})}\cdot \prod_{i=t+1}^{t+m-2}P_{(A_i\neq B_i)}
%  \vspace{-1ex}
\end{eqnarray}
%\normalsize
Under the assumption that $A$ and $B$ are mutually independent and uniformly distributed, we have $P_{(A_i=B_i=1)}=1/4$, $P_{(A_i\neq B_i)}=1/2$ and $P_{(A_i=B_i)}=1/2$, so $P_{tm}$ can be obtained by~(\ref{Ptm2}). Note that~(\ref{Ptm2}) takes into account the carry annihilation always occurs when $t+m-1=n$.
%\vspace{-1ex}
%
\begin{eqnarray}\label{Ptm2}
%\small
%\footnotesize
    P_{tm}=\left\{\begin{array}{ll}
      (1/2)^{m+1} & \textrm{if $t+m-1<n$}\\
      (1/2)^{m} & \textrm{if $t+m-1=n$}
    \end{array} \right.
%    \vspace{-1ex}
\end{eqnarray}
%\normalsize

\subsubsection{Expectation of Overclocking Error}
Expectation of overclocking error can be expressed by (\ref{Eo_exp}).
%
%\vspace{-1ex}
\begin{eqnarray}\label{Eo_exp}
%\small
%\footnotesize
%\scriptsize
    %E_O=\sum_{t=0}^{n-b}\sum_{m=b+1}^{n-t+1}P_{tm}\cdot e_{tm}
    E_O=\sum_{t}\sum_{m}P_{tm}\cdot e_{tm}
%    \vspace{-1ex}
\end{eqnarray}
%\normalsize
%
Using $P_{tm}$ and $e_{tm}$ from (\ref{etm}) and (\ref{Ptm2}) respectively, $E_O$ can be obtained by (\ref{Eo}).
%\vspace{-1ex}
\begin{eqnarray}\label{Eo}
%\small
%\footnotesize
      E_O=\left\{
        \begin{matrix}
            2^{-b}-2^{-n-1}, & \textrm{if $b\leq n$}\\
            0, & \textrm{otherwise}
        \end{matrix}
      \right.
%      \vspace{-1ex}
\end{eqnarray}
%\normalsize

\subsection{Comparison between Two Scenarios}\label{section_RCA_Comparison}
In the traditional scenario, the word-length of RCA must be truncated, using $n=b-1$ bits, in order to meet a given $f_S$. The error expectation is then given by (\ref{Eo_trad_RCA}).
%
\begin{eqnarray}\label{Eo_trad_RCA}
%\small
%\vspace{-1ex}
%\footnotesize
%\scriptsize
  E_{trad}=2^{-b+1}-2^{-k}
  \vspace{-1ex}
\end{eqnarray}
%\normalsize
Overclocking errors are allowed to happen in the second scenario, therefore the word-length of RCA is set to be equal to the input word-length, that is, $n=k$. Hence we obtain (\ref{Eo_new_RCA}) according to (\ref{Eo}).
%
\begin{eqnarray}\label{Eo_new_RCA}
%\vspace{-1ex}
%\small
%\footnotesize
%\scriptsize
  E_{new}=2^{-b}-2^{-k-1}
%  \vspace{-1ex}
\end{eqnarray}
%\normalsize

%
Comparing (\ref{Eo_new_RCA}) and (\ref{Eo_trad_RCA}), we have (\ref{Comparison RCA}). This equation indicates that by allowing timing violations, the overall error expectation of RCA outputs drops by a factor of 2 in comparison to traditional scenario. This provides the first hint that our approach is useful in practice.
%
\begin{eqnarray}\label{Comparison RCA}
%\vspace{-1ex}
%\small
%\footnotesize
%\scriptsize
  \frac{E_{new}}{E_{trad}}=\frac{2^{-b}-2^{-k-1}}{2^{-b+1}-2^{-k}}=\frac{1}{2}
\end{eqnarray}



\section{Carry Select Adder}
\subsection{Introduction}
Since the delay of RCA is determined by the length of carry chain, the parallel adder architectures, such as carry select, carry look-ahead and Kogge-Stone adders, are proposed to boost the performance. For instance, the carry select adder (CSA) is designed with a carry propagation chain being divided and overlapped in sections such that the operating speed can be 

to shorten the carry chain by overlapping carry propagation in sections such that the operating speed can be boosted. The structure of a CSA is presented in Fig.~\ref{Fig_CSA_Structure}. In a CSA, the carry chain is divided into multiple stages. Each stage contains two RCAs and two multiplexers, as seen in Fig.~\ref{Fig_CSA_SingleStage}. For a given input, two computations are performed simultaneously where the carry input is zero and one respectively. One of these two results is then selected according to the actual carry input. Although this structure brings timing benefits, it costs extra hardware resources compared to a standard RCA because the carry chain is duplicated. Furthermore, in FPGA technology, multiplexers are expensive. Due to this reason, we explore the trade-offs between silicon area, accuracy and performance of these two adder structures in this section.

\begin{figure}[htbp]
    \begin{minipage}[b]{.49\textwidth}
        \centering
        \subfigure[The structure diagram of a CSA with $s$ stages.]{
            \includegraphics[width=\textwidth]{./Figures/CSA_structure.pdf}
            \label{Fig_CSA_Structure}
        }\vspace{-3ex}
        \subfigure[The structure of the $i^{th}$ stage in the CSA.]{
        %\centering
            \includegraphics[width=2.4in]{./Figures/CSA_SingleStage.pdf}
            \label{Fig_CSA_SingleStage}
        }
    \end{minipage}
    \centering
    \caption{A comparison between RCA and CSA in terms of the maximum word-length of input signal and the area consumption.}
\end{figure}

%, silicon area is incorporated as the third metric besides accuracy and performance. We explore the trade-offs between these three factors for both adder structures. The objective is to demonstrate the best design choice for a given set of design constraints.

%\begin{figure*}[t]
%  \centering
%  \includegraphics[width=\textwidth]{./Figures/CSAstructure.pdf}
%  \caption{Structure of an $s$-stage CSA.}
%\end{figure*}

%In addition to RCA, there are several

\subsection{Timing Models for Carry Select Adder}
We initially model the CSA in order to understand the relationship between the operating frequency and the maximum word-length of the CSA. This information can then be employed to determine the truncation error based on the models presented in Section~\ref{section_RCA_TruncationError}.

In a CSA with $s$ stages~($s\geqslant 2$), let the stage delay be denoted by $d_{s-1}~\dots,~d_{0}$, where $d_{s-1}$ and $d_{0}$ represent the delay of the most significant and the least significant stages, respectively. In our analysis, we follow the assumption that the critical path delay is due to carry propagation and multiplexing the carry output. Note that unlike other stages, the least significant stage is only built by one RCA without multiplexers, since it is directly driven by the carry input. Hence we obtain the delay of the $i^{th}$ stage as presented in~(\ref{CSA_SingleStageDelay}), where $\mu_{c}$, $\mu_{mux}$ and $n_i$ denote the delay of $1$-bit carry propagation, the delay of multiplexing and the word-length of the $i^{th}$ stage of the CSA, respectively.
\begin{eqnarray}\label{CSA_SingleStageDelay}
  d_i=\left\{
    \begin{matrix}
      n_i\cdot \mu_{c}+(s-i)\cdot\mu_{mux}, &\textrm{if $i\in\left[1,s-1\right]$}\\
      n_0\cdot \mu_c + (s-1)\cdot\mu_{mux}, & \textrm{if $i=0$}
    \end{matrix}
  \right.
\end{eqnarray}

Under the timing-driven design environment, the delay of each stage of CSA is equalized in order to achieve the fastest operation, as presented in~(\ref{CSA_DelayEqual}).
\begin{eqnarray}\label{CSA_DelayEqual}
  d_{s-1}=d_{s-2}=\cdots=d_{0}
\end{eqnarray}

In this case, combining~(\ref{CSA_SingleStageDelay}) and (\ref{CSA_DelayEqual}) yields $n_i$, which is represented by the word-length of the most significant stage $n_{s-1}$, in (\ref{CSA_DelayRep}).
%This design metric also consumes the maximum word-length of CSA for a given frequency, potentially corresponds to the minimum precision loss at inputs. Substituting (\ref{CSA_SingleStageDelay}) into (\ref{CSA_DelayEqual}) yields (\ref{CSA_DelayRep}), where $n_i$ denotes the CSA word-length of stage $i$.
\begin{eqnarray}\label{CSA_DelayRep}
 n_i=\left\{
	\begin{matrix}
	  n_{s-1}-(s-1-i)\cdot\frac{\mu_{mux}}{\mu_c}, & \textrm{if $i\in\left[1,s-1\right]$}\\
	  n_{s-1}-(s-2)\cdot\frac{\mu_{mux}}{\mu_c}, &\textrm{if $i=0$}
	\end{matrix}
    \right.
\end{eqnarray}

Summing up $n_i$ gives the total word-length of the CSA in (\ref{CSA_WL}).
%The total word-length of the CSA is the sum of every stage, as given by (\ref{CSA_WL}).
\begin{eqnarray}\label{CSA_WL}
  \begin{split}
    n_{CSA} &=\sum_{i=0}^{s-1}n_{i} \\
    &= s\cdot n_{s-1}-\frac{\mu_{mux}}{\mu_{c}}\cdot\frac{(s+1)(s-2)}{2}
  \end{split}
\end{eqnarray}

Conventionally under a given frequency constraint, the word-length of RCA is truncated by using $n_{RCA}=b-1$ bits, where $b$ is determined by~(\ref{Max.length of carry chain}). Similarly for CSA, the word-length of each stage should be selected in order to satisfy~(\ref{TimingConstraint_CSA}).
\begin{eqnarray}\label{TimingConstraint_CSA}
  \begin{matrix}
    d_i\leqslant\frac{1}{f_s} &, & \forall i\in[0,s-1]
  \end{matrix}
\end{eqnarray}

Hence for the same frequency requirement, we can form the relationship between the delay of the most significant stage of CSA and the delay of RCA, as given by~(\ref{WL_MSB_CSA}),
\begin{eqnarray}\label{WL_MSB_CSA}
    \mu_c\cdot (b-1) = n_{s-1}\cdot\mu_c+\mu_{mux}
\end{eqnarray}

%, the word-lengths of RCAs and CSAs are selected to avoid timing violation, as presented in~(\ref{CSA_RCA}).

Substitute~(\ref{WL_MSB_CSA}) into (\ref{CSA_WL}) to replace $n_{s-1}$, we derive the representation of the word-length of CSA in terms of a given timing constraint, as presented in~(\ref{CSA_Timing}).
% we form the relationship between the word-length of CSA and RCA under a given timing constraint, as presented in~(\ref{CSA_Timing}).
\begin{eqnarray}\label{CSA_Timing}
  n_{CSA}=s\cdot (b-1)-\frac{\mu_{mux}}{\mu_{c}}\cdot\frac{(s+2)(s-1)}{2}
\end{eqnarray}

%It can be seen that $s=1$ leads to $n_{CSA}=n_{RCA}$. This is because RCA forms the least significant stage of CSA. In addition, combine (\ref{CSA_DelayRep}) and (\ref{CSA_WL}) to ensure $n_{s-1}>0$, we obtain the upper bond of the stage number by~(\ref{CSA_StageNumber}).
%\begin{eqnarray}\label{CSA_StageNumber}
%  s<n_{RCA}\cdot\frac{\mu_c}{\mu_{mux}}+1
%\end{eqnarray}


%\subsection{Model Verification}
%Using this information, we verify our timing model with experimental results, which are obtained from post place and route simulations on Xilinx Virtex-6 FPGAs. Fig.~\ref{CSA Model Verification} illustrates both the modeled value and the experimental results of the maximum word-length of the 2-stage CSA for various operating frequencies. In the following experiments within this section, the input data are randomly sampled from a 16-bit data set, which follows uniform distribution. It can be seen that the the modeled value match well with the experimental results.

%
%\begin{figure}[thbp]
%  \centering
%  \includegraphics[width=3in]{./Figures/Model.eps}
%  \caption{Comparison of the maximum word-length between the modeled value and the experimental results from FPGA simulations.}
%  \label{CSA Model Verification}
%\end{figure}

\subsection{Accuracy Benefits and Area Overhead in CSA}
We first verify the models for RCA and CSA in terms of the maximum word-length under the given operating frequencies. For the CSA, the ratio $\mu_{mux}/\mu_c$ can be computed from experiments. We perform post place-and-route simulations on the CSA with 2 stages using Xilinx Virtex-6 FPGA. The delay of the $i^{th}$ stage $d_i$ in~(\ref{CSA_SingleStageDelay}) is recorded with respect to different word-lengths of this given stage ($n_i$). The total word-length of CSA can be predicted through~(\ref{CSA_Timing}). In addition, the maximum word-lengths of the 2-stage CSA and RCA are obtained experimentally by increasing $n_{CSA}$ and $n_{RCA}$ respectively until errors are observed at the output. The comparison between the modeled value and the empirical results is illustrated in Fig.~\ref{Fig_CSA3stage_Timing} with dotted lines. It can be seen that our models for both RCA and CSA match well with the experimental results.

\begin{figure}[tbp]
    \begin{minipage}[b]{0.48\textwidth}
        \centering
        \subfigure[The modeled value and the experimental results of the maximum word-length of RCA and CSA.]{
            \centering
            \includegraphics[width=0.95\textwidth]{./Figures/CSA3stage_Model_Timing.eps}
            \label{Fig_CSA3stage Timing}
        }
        \subfigure[Hardware resource usage for RCA and CSA with 2 and 3 stages.]{
            \centering
            \includegraphics[width=0.95\textwidth]{./Figures/CSA3stage_Area.eps}
            \label{CSA3stage Area}
        }
    \end{minipage}
    \centering
    \caption{A comparison between RCA and CSA in terms of the maximum word-length of input signal and the area consumption.}
\end{figure}

As greater word-length corresponds to smaller truncation errors, we compare the maximum word-length of RCA and CSA with 2 stages and 3 stages over a range of operating frequencies, as presented in Fig.~\ref{CSA3stage Timing}. It can be seen from Fig.~\ref{CSA3stage Timing} that in comparison to RCA, CSA achieves greater word-length when frequency is initially increased. RCA only outperforms than CSA when very high frequency is applied. This is because at low frequencies, although the multiplexer delay limits the word-length of each stage in CSA when compared to RCA, the stage parallelism in CSA enables a greater word-length. However when frequency increases, the multiplexer delay becomes comparable to the delay of the carry chain, and this inhibits the benefits of parallelism. In addition, we can see that the word-length of 3-stage CSA is always greater than 2-stage CSA across the entire frequency domain.


However, the accuracy benefits brought by CSA comes at the cost of a large area overhead. Fig.~\ref{CSA3stage Area} depicts the number of Look-Up Tables (LUTs) in the FPGA used for all three structures. It can be seen that in order to meet a given frequency, the 3-stage CSA consumes $2.4\times\sim3.7\times$ area than RCA, while the 2-stage CSA requires $1.7\times\sim3.1\times$ extra area. This finding poses a question of which is the best adder structure for a specific area budget.

\subsection{Exploring Trade-offs Between Accuracy, Performance and Area}
In Section~\ref{section_RCA}, we have discussed two design scenarios when considering timing constraints. In this section, we expand our analysis by incorporating the silicon area as another evaluation metric, and investigate the accuracy, performance and area trade-offs for different adder structures. In the conventional design scenario, the word-length of RCA and CSA is limited by the given frequency constraint, or/and the available hardware resources. The precision loss potentially generates large errors even without timing violations. However in the new design scenario, we use RCA with the maximum possible word-length under the given area budget, and the timing constraints are allowed to be violated. This process might result in timing errors as well as truncation errors due to area limitation. We compare these two scenarios with different design goals, with the aim of targeting the optimum design methodology under each situation.

%To answer this question, the silicon area is incorporated into the trade-offs together with accuracy and performance. If the available hardware resources are limited, the full word-length of both CSA and RCA might not be implemented. The precision loss might results in large errors even at low frequencies. This is demonstrated by experiments where area constraints are applied besides the timing requirement. In the conventional design scenario, both of the constraints are met by reducing the word-length of the input signal. The errors at the outputs are recorded with the reference to the original word-length, which is 16 bits in the following experiments. In addition, we propose another circuit designing method where RCA is implemented with the maximum possible word-length under the given area budget, while the timing constraints are met by overclocking.

%Our results could be of interest to a circuit designer in two aspects. On one hand, it is desirable to create a circuit that can run at a given frequency with the minimum achievable output errors and resource usage. On the other hand, the algorithm designer will wish the circuit to operate as fast as possible with the minimum area whilst a certain error budget can be tolerated. We select the optimum design methodology for both situations.

First, suppose the algorithm designer would wish to create a circuit that can run at a given frequency with the minimum achievable output errors and resource usage. That is, a pair of $\{Area, Frequency\}$ constraint is applied. In this case, the optimum design method can be selected based on the following criteria:
\begin{itemize}
  \item Design with the best accuracy at outputs is the optimum design;
  \item If multiple designs achieve the same accuracy, then the design with minimum area is the optimum design;
  \item If the accuracy and area are identical for multiple designs, they are all treated as the optimum design.
\end{itemize}

For instance let the available LUTs number be 25, then the accuracy with respect to different operating frequencies for both design scenarios are presented in Fig.~\ref{CSA_LUT25}, on which the optimum design metric is labeled. Note that the accuracy is defined in terms of the error expectation at the output. In the following experiments within this section, the input data are randomly sampled from a 16-bit data set, which is uniformly distributed.
\begin{figure}[th]
  \centering
  \includegraphics[width=3.3in]{./Figures/Error_LUT25.eps}
  \caption{A comparison between two design scenarios when the number of available LUT is 25. The RCA and CSA are investigated in the conventional scenario, while the RCA is explored in the proposed new scenario. The results are obtained from post place-and-route simulations on Xilinx Virtex-6 FPGAs.}
  \label{CSA_LUT25}
\end{figure}

We first notice that for all frequency values, the overclocked RCA achieves smaller error expectation than the RCA with truncated operand word-lengths, as predicted by the models in Section~\ref{section_RCA_Comparison}. It can also be observed that CSA cannot be implemented with full word-length due to the limited area budget, and this leads to large truncation errors initially for CSA.

We then perform the similar experiments with a variety of area constraints. The optimum design method with respect to different operating frequencies and area consumptions is demonstrated in Fig.~\ref{Fig_CSA_Tradeoff}. From this figure, several observations can be made. If the available area is large enough to implement a CSA in full precision, it will be the optimum design. This is expected from our earlier analysis in Fig.~\ref{CSA3stage Timing}. The 2-stage CSA is better than the 3-stage CSA when frequency is initially increased, as it consumes less area although both of them achieve the same error expectation. For a tighter area budget, only part of the CSA can be implemented, whereas the RCA still keeps full precision. In this case, area becomes the dominate factor and precision is lost for the CSA. We see the RCA with overclocking is the optimum design method across almost the whole frequency domain. For a more stringent area constraint, the word-length of RCA is also limited. This results in truncation errors initially for all design scenarios. However, the RCA with overclocking can still be employed as the optimum design, because it loses less precision than CSA under the same area constraint.
\begin{figure}[t]
  \centering
  \includegraphics[width=3.5in]{./Figures/Tradeoff.eps}
  \caption{A demonstration of the optimum design methodology which achieves the minimum error at outputs with respect to a variety of frequency and area constraints.}
  \label{Fig_CSA_Tradeoff}
\end{figure}

Similarly if the design goal is to operate the circuit as fast as possible with the minimum area whilst a certain error budget can be tolerated, the optimum design methodology can be decided as illustrated in Fig.~\ref{Fig_CSA_Tradeoff_Error}. In this situation, the error specifications are evaluated in terms of the mean relative error (MRE), as presented in~(\ref{MRE}), where $E_{error}$ and $E_{out}$ refer to the mean value of error and the mean value of outputs, respectively.
\begin{eqnarray}\label{MRE}
  MRE=\left|\frac{E_{error}}{E_{out}}\right|\times 100\%
\end{eqnarray}

In our experiments, MRE is set ranging from $0.001\%$ to $50\%$. For a certain MRE, the design with the maximum operating frequencies is selected as the optimum design. Moreover, the smallest design is the optimum one if multiple structures operate at the same frequency, with a certain area requirement. Fig.~\ref{Fig_CSA_Tradeoff_Error} can thus be obtained based on these criteria.
%Based on these criteria, the decision graph is depicted in
%We also notice that for small frequencies, RCA with either overclocking or truncation of word-length of the input signal is the best design choice for any area constraint, since
\begin{figure}[t]
    \centering
    \includegraphics[width=3.5in]{./Figures/Tradeoff_Error.eps}
    \caption{A demonstration of the optimum design methodology which runs at the fastest frequency with respect to a variety of accuracy and area constraints.}
    \label{Fig_CSA_Tradeoff_Error}
\end{figure}

For a tight accuracy requirement, i.e. $MRE<0.005\%$, CSA serves as the optimum design choice with respect to large accessible area, as it intrinsically operates faster than RCA. Once again, when the area budget shrinks, the RCA performs best because the precision of the CSA is limited. Similarly to the previous section, we see that the overclocked RCA achieves the fastest operating frequencies under most area constraints when the accuracy requirement is released.

To sum up, the experiments reveal that for both design goals, CSA is the best option only when there is enough hardware resources. However this circumstance is unlikely to happen, especially with the continued technology scaling nowadays. Due to this reason, in the following sections we will focus on the situation where the hardware resources are limited, and therefore RCA is the design option in our following analysis and experiments.

\section{Constant Coefficient Multiplier}\label{section_CCM}

As another key primitive of arithmetic operations, CCM can be implemented using RCA and shifters. For example, operation $B=9A$ is equivalent to $B=A+8A=A+(A<<3)$, which can be built using one RCA and one shifter. We first focus on a single RCA and single shifter structure. We describe how more complex structures consisting of multiple RCAs and multiple shifters can be built in accordance with this baseline structure in Section~\ref{CCM_Multi}.

In this CCM structure, let the two inputs of the RCA be denoted by $A_S$ and $A_O$ respectively, which are both two's complement numbers. $A_S$ denotes the ``shifted signal", with zeros padded after LSB, while $A_O$ denotes the ``original signal" with MSB sign extension. For an $n$-bit input signal, it should be noted that an $n$-bit RCA is sufficient for this operation, because no carry will be generated or propagated when adding with zeros, as shown in Figure~\ref{CCM_fig}.
\begin{figure}[htbp]
  \centering
%  \vspace{-2ex}
  %\includegraphics[width=3.5in]{./Figures/CCM_DataFlow3.pdf}
  \includegraphics[width=3.3in]{./Figures/CCM_DataFlow3.eps}
%  \vspace{-2ex}
  \caption{Different types of carry chain in constant coefficient multiplier. The notion $s$ denotes the shifted bits and $BP$ denotes the binary point.}
  \label{CCM_fig}
%  \vspace{-1.5ex}
\end{figure}

\subsection{Probabilistic Model of Truncation Error}
Let $E_{Tin}$ and $E_{Tout}$ denote the expectation of truncation error at the input and output of CCM respectively. We then have (\ref{Et_CCM}), where $coe$ denotes the coefficient value of the CCM, and $E_{Tin}$ can be obtained according to~(\ref{TruncationError}).
%
\begin{eqnarray}\label{Et_CCM}
%\vspace{-1ex}
%\small
%\footnotesize
%\scriptsize
  E_{Tout}=|coe|\cdot E_{Tin}
%  \vspace{-1ex}
\end{eqnarray}
%\normalsize

\subsection{Probabilistic Model of Overclocking Error}
\subsubsection{Absolute Value of Overclocking Error}
The absolute value of overclocking error of carry chain $C_{tm}$ is increased by a factor of $2^s$ due to shifting, compared to RCA. Hence $e_{tm}$ in CCM can be modified from (\ref{etm}) to give (\ref{etm_CCM}).
%
\begin{eqnarray}\label{etm_CCM}
%\vspace{-1ex}
%\small
%\footnotesize
  e_{tm}=2^{t+b-n+s}
%  \vspace{-1.5ex}
\end{eqnarray}
%\normalsize

\subsubsection{Probability of Overclocking Error}
Due to the dependencies in a CCM, carry generation requires $a_t=a_{t-s}=1$, propagation and annihilation of a carry chain is best considered separately for four types of carry chain generated at bit~$t$. We label these by $C_{tm}1$ to $C_{tm}4$ in Figure~\ref{CCM_fig}, defined by the end region of the carry chain. For $C_{tm}1$, we have:
\begin{itemize}
  \item Carry propagation: $\!a_i\neq\!a_{i+s}\!$ where $\!i\!\in[t+1,n-s-2]\!$;
  \item Carry annihilation: $\!a_j\!=\!a_{j+s}\!$ where $\!j\!\in[t+1,n-s-1]\!$.
\end{itemize}
Similarly for $C_{tm}2$, we have:
\begin{itemize}
  \item Carry propagation: $a_i\neq a_{n-1}$ where $i\in[n-s-1,n-3]$; or $a_i\neq a_{i+s}$ where $i\in[t+1,n-s-2]$;
  \item Carry annihilation: $\!a_j\!=a_{n-1}\!$ where $j\!\in\![n-s-1,n-2]$.
\end{itemize}

For the first two types of carry chain $C_{tm}1$ and $C_{tm}2$, the probability of carry propagation and annihilation is $1/2$ and the probability of carry generation is $1/4$, under the premise that all bits of input signal are mutually independent. Therefore (\ref{Ptm_CCM1}) can be obtained by substituting this into~(\ref{Ptm_RCA}).
%
\begin{eqnarray}\label{Ptm_CCM1}
%\vspace{-1ex}
%\small
%\footnotesize
  P_{tm}=\left(1/2\right)^{m+1}, & \textrm{if $t+m-1\leqslant n-2$}
\end{eqnarray}
%\normalsize

For carry annihilation of $C_{tm}3$, $a_{n-1}=a_{n-1}$, which is always true. Thus the probability of $C_{tm}3$ is given by (\ref{Ptm_CCM2}).
%
\begin{eqnarray}\label{Ptm_CCM2}
%\vspace{-1ex}
%\small
%\footnotesize
  P_{tm}=\left(1/2\right)^m, & \textrm{if $t+m-1=n-1$}
%  \vspace{-1ex}
\end{eqnarray}
%\normalsize
$C_{tm}4$ represents carry chain annihilates over $a_{n-1}$, therefore carry propagation requires $a_{n-1}\neq a_{n-1}$. This means $C_{tm}4$ never occurs in a CCM.

Altogether, $P_{tm}$ for a CCM is given by (\ref{Ptm_CCM}).
\begin{eqnarray}\label{Ptm_CCM}
%\small
  P_{tm}=\left\{\begin{array}{ll}
      (1/2)^{m+1} & \textrm{if $t+m-1<n-1$}\\
      (1/2)^{m} & \textrm{if $t+m-1=n-1$}
    \end{array} \right.
    %\vspace{-1ex}
\end{eqnarray}
%\normalsize

\subsubsection{Expectation of Overclocking Error}
Since the carry chain of a CCM will not propagate over $a_{n-1}$, the upper bound of parameter $t$ and $m$ should be modified from (\ref{t_RCA}) and (\ref{m_RCA}) to give (\ref{t_CCM}) and (\ref{m_CCM}).
%
\begin{eqnarray}
%\vspace{-1ex}
%\small
%\footnotesize
%\scriptsize
  \label{t_CCM} 0\leqslant t\leqslant n-b-1\\
  \label{m_CCM} b<m\leqslant n-t
%  \vspace{-1ex}
\end{eqnarray}
%\normalsize

Finally, by substituting (\ref{Ptm_CCM}) and (\ref{etm_CCM}) with modified bounds of $t$ and $m$ into (\ref{Eo_exp}), we obtain the expectation of overclocking error for a CCM to be given by (\ref{Eo_CCM}).
%
\begin{eqnarray}\label{Eo_CCM}
%\vspace{-1ex}
%\small
%\footnotesize
      E_O=\left\{
        \begin{matrix}
            2^{s-b-1}-2^{s-n-1}, & \textrm{if $b\leq n-1$}\\
            0, & \textrm{otherwise}
        \end{matrix}
      \right.
%      \vspace{1ex}
\end{eqnarray}
%\normalsize

\subsection{CCM with Multiple RCAs and Shifters}\label{CCM_Multi}
In the case where a CCM is composed of two shifters and one RCA, such as operation $\!B\!=\!20A\!=\!(\!A<<2)+(\!A<<4)$, let the shifted bits be denoted as $s_1$ and $s_2$ respectively. Hence the equivalent $s$ in (\ref{Eo_CCM}) can be obtained through~(\ref{ShiftNo}).
%
%\vspace{-3ex}
\begin{eqnarray}\label{ShiftNo}
%\footnotesize
%\scriptsize
  s=\left|s_1-s_2\right|
%  \vspace{-1ex}
\end{eqnarray}

For those operations such as $B=37A=(A<<5)+(A<<2)+(A<<1)$, the CCM can be built using a tree structure. Each root node is the baseline CCM and the errors are propagated through an adder tree, of which the error can be determined based on our previous RCA model.

\section{Test Platform}\label{Experiment}
In our experiments, we compare two design perspectives. In the first scenario, the word-length of the input signal is truncated before propagating through the datapath in order to meet a given latency. In our proposed overclocking scenario, the circuit is overclocked while keeping the original operand word-length. The benefits of the proposed methodology are demonstrated over a set of DSP example designs, which are implemented on the Xilinx ML605 board with a Virtex-6 FPGA XC6VLX240T-1FFG1156.

\subsection{Experimental Setup} % (fold)
\label{sub:experimental_setup}
We initially build up a test framework on an FPGA. The general architecture is depicted in Fig.~\ref{Test Framework}. The main body of the test framework consists of the circuit under test (CUT), the test frequency generator and the control logic, as shown in the dotted box in Fig.~\ref{Test Framework}. The I/Os of the CUT are registered by the launch registers (LRs) and the sample registers (SRs), which are all triggered by the test clock. Input test vectors are stored in the on-chip memory during initialization. The results are sampled using Xilinx ChipScope. Finally, we perform an offline comparison of the output of the original circuit at the rated frequency with the output of the overclocked as well as the truncated designs using the same input vectors.
%
\begin{figure}[htbp]
  \centering
  %\vspace{-3.5ex}
  \includegraphics[width=3.3in]{./Figures/TestFramework2.eps}
  %\vspace{-4.5ex}
  \caption{FPGA Test framework, which is composed of a measurement architecture (the dotted box) and an off-line comparator.}
  \label{Test Framework}
  %\vspace{-1ex}
\end{figure}

The test frequency generator is implemented using two cascaded mixed-mode clock managers (MMCMs), created using Xilinx Core Generator~\cite{Virtex6Clocking}. Besides the outputs, the corresponding input vectors and memory addresses are also recorded into the comparator, as can be seen in Fig.~\ref{Test Framework}, in order to ensure that the recorded errors arise from overclocking the CUT rather than the surrounding circuitry when high test frequencies are applied.

%the potential timing errors generated from the test framework instead of CUT, when high test frequencies are applied. Comparisons are performed between the sampled results and the expected values. If mismatch is found, the results will be discarded.

%. In this test framework, two cascaded MMCMs are employed in order to provide a wide range of frequency values. In addition, the output frequency of the MMCM can be dynamically reconfigured without re-implementing the whole design~\cite{Virtex6Clocking,MMCM}. This reconfiguration process is controlled by a finite state machine within the control logic. Before actual measurements on FPGA, the rated frequency of CUT is examined through Xilinx Timing Analyzer. This frequency is then utilized as the starting value when generating test frequencies. The new frequency will increase with a step of 10MHz and stop when the comparator shows that output errors are stabilized. The control logic also generates address and read enable signal for the on-chip memory.

%In our experiments, the test clock frequency starts from the rated operating frequency of CUT, and increases with a step of 10MHz until the output error expectation stabilizes.

%In order to avoid the potential timing errors generated from the test framework instead of CUT under high test frequencies, several methods are adopted. Firstly, the control signals for the test frequency generator is triggered by the system clock, which is 33.33MHz in our experiments. This will guarantee that the test clock generation will not be affected by high frequencies. Secondly, since the address counter for the on-chip memory is driven by the test frequency, a deeply pipelined counter structure with initial delay of 258 cycles is used to ensure the correct sample of each address bit. Thirdly, the key internal control signals such as memory address and corresponding operands are recorded together with the outputs to the comparator. Comparisons are performed between these values and the corresponding original values. The results will be discarded if mismatch is found.
% without reimplement the whole design.
% subsection experimental_setup (end)
% \subsection{Experimental Results} % (fold)
% \label{sub:subsubsection_name}

\subsection{Benchmark Circuits}
Three types of DSP designs are tested: digital filters (FIR, IIR and Butterworth), a Sobel edge detector and a direct implementation of a Discrete Cosine Transformation (DCT). The filter parameters are generated through MATLAB filter design toolbox, and they are normalized to integers for implementation. Table~\ref{Rated_Frequency_table} summarizes the operating frequency of each implemented design in Xilinx ISE14.1 when the word-length of input signal is 8-bit.
\vspace{-0.5ex}
\begin{table}[htbp]
%% increase table row spacing, adjust to taste
\renewcommand{\arraystretch}{1.2}
%\setlength{\tabcolsep}{2}
\caption{Rated Frequencies of Example Designs.}
\label{Rated_Frequency_table}
\begin{center}
\footnotesize
%\vspace{-4ex}
\begin{tabular}{ccc}
\hline
\hline
Design & Frequency (MHz) & Description\\
\hline
FIR Filter & 126.2 & $5^{th}$ order\\
Sobel Edge Detector & 196.7 & $3\times 3$\\
IIR Filter & 140.3 & $7^{th}$ order\\
Butterworth Filter & 117.1 & $9^{th}$ order\\
DCT & 176.7 & 4-point\\
\hline
\hline
\end{tabular}
\normalsize
\end{center}
%\vspace{-2.5ex}
\end{table}

The input data are generated from two sources. One is called ``uniform independent inputs'', which are randomly sampled from a uniform distribution of 8-bit numbers. The other is referred to as ``real inputs'', which denote 8-bit pixel values of the $512\! \times\! 512$ Lena image.

\subsection{Exploring the Conservative Timing Margin} % (fold)
\label{sub:exploring_the_conservative_timing_margin}

Generally, the operating frequency provided by EDA tools tends to be conservative to ensure the correct functionality under a wide range of operating environments and workloads. In a practical situation, this may result in a large gap between the predicted frequency and the actual frequency under which the correct operation is maintained~\cite{gojman2013FPGA}.

For example, the predicted frequencies and the actual frequencies of a $5^{th}$~order FIR filter using different word-lengths are depicted in Fig.~\ref{TimingMargin}. The ``actual'' maximum frequencies are computed by increasing the operating frequency from the rated value until errors are observed at the output; the maximum operating frequency with correct output is recorded for the current word-length. As can be seen in Fig.~\ref{TimingMargin}, the circuit can operate without errors at a much higher frequency in practice than predicted according to our experiments. A maximum speed differential of $3.2\times$ is obtained when the input signal is 5-bit.

\begin{figure}[t]
  \centering
  \includegraphics[width=3.2in]{./Figures/Exp/FIR/RatedFrequency3.eps}
  %\vspace{-1.5ex}
  \caption{The maximum operating frequencies for different input word-lengths of an FIR filter. The dotted line depicts the rated frequency reported by the Xilinx Timing Analyzer. The solid line is obtained through real FPGA tests using our platform.}
  \label{TimingMargin}
  %\vspace{-3.5ex}
\end{figure}

In our experiments in Section~\ref{Section_Experiments}, the conservative timing margin is removed in the traditional scenario for a fairer comparison to the overclocking scenario. To do this, for each truncated word-length, we select the maximum frequency at which we see no overclocking error on the FPGA board in our lab. For example, in Fig.~\ref{TimingMargin}, the operating frequency of the design when the word-lengths are truncated to 8,~5 and 2 bits are 400MHz,~450MHz and 500MHz respectively.

Fig.~\ref{TimingMargin} also demonstrates that when the circuit is truncated, it allows the circuit to operate at a higher frequency than the frequency of full precision implementation. However, a non-uniform period change can be observed for both results. For instance, the maximum operating frequency keeps almost constant when the operand word-length reduces from 8 to 6 or from 5 to 3 in both the experimental results and those of timing analyzer. This will cause a slight deviation between our analytical model which assumes that the single bit carry propagation delay to be a constant value, as discussed in (\ref{Eo_trad_RCA}) with expression $n=b-1$. This deviation will be influenced by many factors including how the architecture has been packed onto LUTs and CLBs and process variation causing non-uniform interconnection delays~\cite{FPGAPV}. However, we shall see that our model remains close to the true empirical results in Section~\ref{Section_Experiments}.



\subsection{Evaluation Metric of Outputs}
The results are evaluated in terms of mean relative error (MRE), which represents the percentage of error at outputs. MRE is given by~(\ref{MRE}), where $E_{error}$ and $E_{out}$ refer to the mean value of error and the correct output respectively.
%
\begin{eqnarray}\label{MRE}
%\small
\scriptsize
  MRE=\left|\frac{E_{error}}{E_{out}}\right|\times 100\%
\end{eqnarray}
\normalsize

\subsection{Computing Model Parameters}
The accuracy of our proposed models is examined with practical results on Virtex-6 FPGA. We first determine the model parameters. There are two types of parameters in the models of overclocking error. The first is based on the circuit architecture. For example, the word-length of RCAs and CCMs ($n$), the shifted bits of the shifters in CCM ($s$), and the word-length of the input signal ($k$). This is determined through static analysis. The second depends on timing information, such as the single bit carry propagation delay $\mu$. In order to keep consistency with the assumption made in models that $\mu$ is a fixed value, it is obtained according to the actual FPGA measurement results.

Initially the maximum error-free frequency $f_0$ is applied. In this case we have~(\ref{Eq_decideMu_0}) where $d_c$ is a constant value which denotes the interconnection delay. The frequency is then increased such that~(\ref{Eq_decideMu_1}) is obtained. This process repeats until the maximum frequency $f_{n-1}$ is applied in~(\ref{Eq_decideMu_2}). Based on these frequency values, $\mu$ can be determined.
\begin{eqnarray}\label{Eq_decideMu_0}
\vspace{-1ex}
%\small
%\footnotesize
\scriptsize
  f_0 &= n\mu+d_c
  \vspace{-12ex}
\end{eqnarray}
\vspace{-5ex}
\begin{align}\label{Eq_decideMu_1}
  f_1 &= (n-1)\mu+d_c    \\
  &\cdots               \notag
  \vspace{-3ex}
\end{align}
\vspace{-5.5ex}
\begin{eqnarray}\label{Eq_decideMu_2}
  f_{n-1} &= \mu+d_c
%  \vspace{-2ex}
\end{eqnarray}
\normalsize

\section{Results and Discussion}\label{Section_Experiments}
\subsection{Case study: FIR filter}
We first assess the accuracy of our proposed models of error. The modeled values of both overclocking error and truncation error of the FIR filter are presented in Fig.~\ref{FIR} (dotted lines), as well as the actual measurements on the FPGA (solid lines) with two types of input data. The results demonstrate that our models match well with the practical results obtained using the uniform independent inputs.
% FIR
\begin{figure}[htbp]
  \centering
%  \vspace{-2.5ex}
  \includegraphics[width=3.5in]{./Figures/Exp/FIR/FIR_Error_New2.eps}
%  \vspace{-5ex}
  \caption{A demonstration of two design perspectives with a $5^{th}$~order FIR filter, which is implemented on Virtex-6 FPGA. The modeled values of both overclocking errors and truncation errors are presented as dotted lines. The actual FPGA measurements are depicted using solid lines. Two types of inputs are employed in the overclocking scenario: the uniformly distributed data and the real image data from Lena.}
  \label{FIR}
%  \vspace{-1ex}
\end{figure}

%Lena image
\begin{figure*}[htbp]
  %\vspace{-2ex}
  \centering
  \subfigure[425MHz,~n=8~,~no errors observed]{
  \begin{minipage}[c]{0.24\textwidth}
    \centering
    \includegraphics[width=1.8in]{./Figures/Exp/FIR/LenaImages/FIRLena_T8.eps}
  \end{minipage}%
  }% This is important! use % to indicate same line, otherwise new line
  \subfigure[430MHz,~n=8,~SNR=47.15dB]{
  \begin{minipage}[c]{0.24\textwidth}
    \centering
    \includegraphics[width=1.8in]{./Figures/Exp/FIR/LenaImages/FIRLena_T65.eps}
  \end{minipage}
  }%
  \subfigure[480MHz,~n=8,~SNR=24.1dB]{
  \begin{minipage}[c]{0.24\textwidth}
    \centering
    \includegraphics[width=1.8in]{./Figures/Exp/FIR/LenaImages/FIRLena_T62.eps}
  \end{minipage}
  }%
  \subfigure[520MHz,~n=8,~SNR=10.86dB]{
  \begin{minipage}[c]{0.24\textwidth}
    \centering
    \includegraphics[width=1.8in]{./Figures/Exp/FIR/LenaImages/FIRLena_T6.eps}
  \end{minipage}
  }\vspace{-1ex}
  \subfigure[425MHz,~n=7,~SNR=26.06dB]{
  \begin{minipage}[c]{0.24\textwidth}
    \centering
    \includegraphics[width=1.8in]{./Figures/Exp/FIR/LenaImages/FIRLena_Q7T10.eps}
  \end{minipage}%
  }% This is important! use % to indicate same line, otherwise new line
  \subfigure[430MHz,~n=5,~SNR=24.85dB]{
  \begin{minipage}[c]{0.24\textwidth}
    \centering
    \includegraphics[width=1.8in]{./Figures/Exp/FIR/LenaImages/FIRLena_Q4T10.eps}
  \end{minipage}
  }%
  \subfigure[480MHz,~n=2,~SNR=6.57dB]{
  \begin{minipage}[c]{0.24\textwidth}
    \centering
    \includegraphics[width=1.8in]{./Figures/Exp/FIR/LenaImages/FIRLena_Q2T10.eps}
  \end{minipage}
  }%
  \subfigure[520MHz,~n=1,~SNR=3.95dB]{
  \begin{minipage}[c]{0.24\textwidth}
    \centering
    \includegraphics[width=1.8in]{./Figures/Exp/FIR/LenaImages/FIRLena_Q1T10.eps}
  \end{minipage}
  }
%\vspace{-2ex}
\caption{Output images of the FIR filter for both overclocking scenario (top row) and traditional scenario (bottom row) under various operating frequencies.}
\label{FIR_Lena}
%\vspace{-2ex}
\end{figure*}

According to Fig.~\ref{FIR}, output errors are reduced in the overclocking scenario for both input types in comparison to the traditional scenario, as the analytical model validates. In addition, we see that using real data, more significant reduction of MRE are achieved, and that no errors are observed when frequency is initially increased. This is because for real data, long carry chains are typically generated with even smaller probabilities, and the longest carry chain rarely occurs.

The output images of the FIR filter for both of the two scenarios with increasing frequencies are presented in Fig.~\ref{FIR_Lena}, from which we can clearly see the differences between the errors generated in these two scenarios. In the overclocking scenario, we observe errors in the MSBs for certain input patterns. This leads to ``salt and pepper noise'', as shown on the images in the top row of Fig.~\ref{FIR_Lena}. In the traditional scenario, truncation causes an overall degradation of the whole image, as can be seen in the bottom row of Fig.~\ref{FIR_Lena}. Furthermore, it is difficult to recover from the latter type of error, since it is generated due to precision loss.


\subsection{Potential Benefits in Circuit Design}
%The results can be interpreted in two folds.
Our results could be of interest to a circuit designer in two ways. Typically, either the designer will want to create a circuit that can run at a given frequency with the minimum possible MRE, or the algorithm designer will wish to run as fast as possible whilst maintaining a specific error tolerance. In the first case, the experimental results for all five example designs on FPGA are summarized in Table~\ref{Ratio_MRE} in terms of the relative reduction of MRE as given in~(\ref{Relative Reduction MRE}) where $MRE_{Trad}$ and $MRE_{ovrc}$ denote the value obtained in the traditional scenario and in the overclocking scenario, respectively.
\begin{eqnarray}\label{Relative Reduction MRE}
%\small
\scriptsize
  \frac{MRE_{Trad}-MRE_{ovrc}}{MRE_{Trad}}\times 100\%
\end{eqnarray}
\normalsize
%\vspace{-2ex}

In this table, the frequency is normalized to the maximum error-free frequency for each design when the input signal is 8-bit. The N/A in Table~\ref{Ratio_MRE} refers to the situations where a certain frequency simply cannot be achieved using the traditional scenario. It can be seen that a significant reduction of MRE can be achieved using the proposed overclocking scenario, and the geometric mean reduction varies from $67.9\%$ to $95.4\%$ using uniform input data. Even larger differences of MRE can be observed when testing with real image data for each design, ranging from $83.6\%$ to $98.8\%$, as expected given the results shown in Fig.~\ref{FIR}.
%Table goes here

\begin{table*}[htbp]
 %\vspace{-2ex}
 %% increase table row spacing, adjust to taste
   \renewcommand{\arraystretch}{1.05}
   \setlength{\tabcolsep}{3.5pt}
   \caption{Relative Reduction of MRE in Overclocking Scenario for Various Normalized Frequencies Based on~(\ref{Relative Reduction MRE}).}
%   \vspace{-2ex}
   \centering
   \footnotesize
   %\vspace{-4mm}
   \begin{threeparttable}
   \begin{tabular}{c|cc|cc|cc|cc|cc||cc}
     \hline
     \hline
     \multirow{2}*{\begin{tabular}{c}\textbf{Normalized}\\\textbf{Frequency}\end{tabular}} &
     \multicolumn{2}{c|}{\textbf{FIR}} &
     \multicolumn{2}{c|}{\textbf{Sobel}} &
     \multicolumn{2}{c|}{\textbf{IIR}} &
     \multicolumn{2}{c|}{\textbf{Butterworth}} &
     \multicolumn{2}{c||}{\textbf{DCT4}} &
     \multicolumn{2}{c}{\textbf{Geo.Mean}}\\
     &  {Uniform} & {Lena } &  {Uniform} & {Lena } &  {Uniform} & {Lena  }
     &  {Uniform} & {Lena } &  {Uniform} & {Lena } &  {Uniform} & {Lena}\\
     \hline
     1.04 & 99.85\%	& 100.00\%  & 99.51\% &	99.74\% &	 72.28\% &	90.09\% &	 79.03\% &	 100.00\% &	 83.58\% &	 98.06\% & 86.14\% & 97.50\%\\
     1.08 & 98.93\%	& 99.97\%	& 96.26\% &	93.75\% &	 71.64\% &	90.50\% &	 78.81\% &	 100.00\% &	 83.26\% &	 98.45\% & 85.15\% & 96.46\%\\
     1.12 & 94.27\%	& 98.82\%   & 96.25\% &	93.62\% &	 73.63\% &   88.25\% &	 81.88\% &	 84.87\%  &	 89.44\% &	 99.56\% & 86.68\% & 92.84\%\\
     1.16 & 99.66\%	& 99.91\%   & 73.73\% &	93.62\% &	 73.10\% &   89.92\% &	 79.30\% &	 84.23\%  &	 79.07\% &	 99.44\% & 80.44\% & 93.23\%\\
     1.20 & 96.03\%	& 99.90\%   & 81.55\% &	81.52\% &	 70.76\% &	75.67\% &	 64.96\% &	 84.50\%  &	 N/A\tnote{*}	  & N/A\tnote{*} & 77.46\% & 84.95\% \\
     1.24 & 98.46\%	& 99.32\%   & 81.43\% &	81.67\% &	 70.47\% &	76.12\% &	 63.66\% &	 84.23\%  &	 N/A\tnote{*}	  & N/A\tnote{*} & 77.44\% & 84.92\%\\
     1.28 & 95.39\%	& 99.29\%   & 60.41\% &	78.24\% &	 N/A\tnote{*}	    &   N/A\tnote{*}     &	54.38\% &	 75.15\%  &	N/A\tnote{*}	  & N/A\tnote{*} & 67.92\% & 83.58\%\\
     1.32 & 95.37\%	& 98.75\%   & N/A\tnote{*}	  &	 N/A\tnote{*}	    &	 N/A\tnote{*}	    &	 N/A\tnote{*}   & N/A\tnote{*}   & N/A\tnote{*}    &    N/A\tnote{*}   & N/A\tnote{*} & 95.37\%	& 98.75\% \\
     \hline
     \hline
   \end{tabular}
   \normalsize
   \begin{tablenotes}
   \footnotesize
    \item[*] Current frequency cannot be achieved in the traditional scenario. These points are excluded from the calculation of geometric means.
   \end{tablenotes}
   \end{threeparttable}
   \label{Ratio_MRE}
% \vspace{-1ex}
 \end{table*}

\begin{table*}[htbp]
 %\vspace{-2ex}
 %% increase table row spacing, adjust to taste
   \renewcommand{\arraystretch}{1.05}
   \setlength{\tabcolsep}{3.5pt}
   \caption{Frequency Speedups in Overclocking Scenario Under Various Error Budgets.}
%   \vspace{-2ex}
   \label{Exp_Real_Inputs}
   \centering
   \footnotesize
   \begin{tabular}{c|cc|cc|cc|cc|cc||cc}
     \hline
     \hline
     \multirow{2}*{\begin{tabular}{c}\textbf{Error Budget}\\\textbf{\%}\end{tabular}} &
     \multicolumn{2}{c|}{\textbf{FIR}} &
     \multicolumn{2}{c|}{\textbf{Sobel}} &
     \multicolumn{2}{c|}{\textbf{IIR}} &
     \multicolumn{2}{c|}{\textbf{Butterworth}} &
     \multicolumn{2}{c||}{\textbf{DCT4}} &
     \multicolumn{2}{c}{\textbf{Geo.Mean}} \\
     %\multirow{2}*{\begin{tabular}{c}\textbf{Geo.}\\\textbf{Mean}\end{tabular}}\\
     & {Uniform} & {Lena } &  {Uniform} & {Lena } &  {Uniform} & {Lena  }
     & {Uniform} & {Lena } &  {Uniform} & {Lena } &  {Uniform} & {Lena }\\
     \hline
     0.05 & 4.76\%&	21.43\%&	 6.82\%&	6.82\%&	0.95\%&	 1.26\%&	12.40\%&	 24.03\%&	 0.72\%&	 0.96\%  &3.07\%    &5.32\%\\
     0.5  & 19.05\%&	21.43\%&	 13.64\%&	6.82\%&	0.63\%&	 10.06\%&	24.03\%&	 24.03\%&	0.48\%&	 12.44\%   &4.52\% &13.45\%\\
     1    & 19.05\%&	28.57\%&	 13.64\%&	18.18\%&	 10.06\%&	16.35\%&	 24.03\%&	 24.03\%&	 0.48\%&	 12.44\%    &7.86\% &19.10\%\\
     5    & 19.15\%&	25.53\%&	 18.18\%&	18.18\%&	 0.54\%&	0.82\%&	 0.63\%&	 0.94\%&	 7.66\%&	 12.44\%    &3.91\%    &5.36\%\\
     10   & 19.15\%&	25.53\%&	 10.64\%&	10.64\%&	 0.54\%&	1.09\%&	 6.92\%&	 13.21\%&	 4.91\%&	 4.911\%    &5.19\%    &7.19\%\\
     20   & 19.15\%&	25.53\%&	 5.77\%&	15.39\%&	 8.70\%&	8.70\%&	 3.26\%&	 3.26\%&	 6.70\%&	 10.88\%    &7.32\%    &10.39\%\\
     50   & 15.69\%&	15.69\%&	 10.53\%&	19.30\%&	 42.50\%&	50.00\%&	 46.74\%&	 54.89\%&	 15.06\%&	 19.25\%    &21.8\% &27.59\%\\
     \hline
     \hline
   \end{tabular}
   \normalsize
   \label{Max_Frequency}
%   \vspace{-3ex}
 \end{table*}

Table~\ref{Max_Frequency} illustrates the frequency speedups for each design when the specified error tolerance varies from 0.05\% to 50\%. For all designs, we see that the overclocking scenario still outperforms the traditional scenario for each MRE budget in terms of operating frequency. Likewise, the frequency speedup is higher for real image inputs than uniform inputs. The geometric mean of frequency speedups of $3.1\%$ to $21.8\%$ can be achieved by using uniform data, while $5.3\%$ to $27.6\%$ when using real image data.

\section{Conclusion}
The conclusion goes here.

\section*{Acknowledgment}
The authors would like to acknowledge the support of the EPSRC (Grants EP/I020557/1 and EP/I012036/1).

%\begin{figure}[htbp]
%	\centering
%	\includegraphics[width=3.3in]{./Figures/Error_LUT45.eps}
%	\caption{LUT=45}
%\end{figure}
%
%\begin{figure}[htbp]
%	\centering
%	\includegraphics[width=3.3in]{./Figures/Error_LUT35.eps}
%	\caption{LUT=35}
%\end{figure}
%
%\begin{figure}[htbp]
%	\centering
%	\includegraphics[width=3.3in]{./Figures/Error_LUT25.eps}
%	\caption{LUT=25}
%\end{figure}
%
%\begin{figure}[htbp]
%	\centering
%	\includegraphics[width=3.3in]{./Figures/Error_LUT15.eps}
%	\caption{LUT=15}
%\end{figure}
%



%\begin{figure}[!t]
%\centering
%\includegraphics[width=2.5in]{myfigure}
% where an .eps filename suffix will be assumed under latex,
% and a .pdf suffix will be assumed for pdflatex; or what has been declared
% via \DeclareGraphicsExtensions.
%\caption{Simulation Results.}
%\label{fig_sim}
%\end{figure}


% An example of a double column floating figure using two subfigures.
% (The subfig.sty package must be loaded for this to work.)
% The subfigure \label commands are set within each subfloat command,
% and the \label for the overall figure must come after \caption.
% \hfil is used as a separator to get equal spacing.
% Watch out that the combined width of all the subfigures on a
% line do not exceed the text width or a line break will occur.
%
%\begin{figure*}[!t]
%\centering
%\subfloat[Case I]{\includegraphics[width=2.5in]{box}%
%\label{fig_first_case}}
%\hfil
%\subfloat[Case II]{\includegraphics[width=2.5in]{box}%
%\label{fig_second_case}}
%\caption{Simulation results.}
%\label{fig_sim}
%\end{figure*}
%


% An example of a floating table. Note that, for IEEE style tables, the
% \caption command should come BEFORE the table. Table text will default to
% \footnotesize as IEEE normally uses this smaller font for tables.
% The \label must come after \caption as always.
%
%\begin{table}[!t]
%% increase table row spacing, adjust to taste
%\renewcommand{\arraystretch}{1.3}
% if using array.sty, it might be a good idea to tweak the value of
% \extrarowheight as needed to properly center the text within the cells
%\caption{An Example of a Table}
%\label{table_example}
%\centering
%% Some packages, such as MDW tools, offer better commands for making tables
%% than the plain LaTeX2e tabular which is used here.
%\begin{tabular}{|c||c|}
%\hline
%One & Two\\
%\hline
%Three & Four\\
%\hline
%\end{tabular}
%\end{table}




% references section
\bibliographystyle{./IEEEtran}
\bibliography{./IEEEabrv,./Reference}


% biography section
%
% If you have an EPS/PDF photo (graphicx package needed) extra braces are
% needed around the contents of the optional argument to biography to prevent
% the LaTeX parser from getting confused when it sees the complicated
% \includegraphics command within an optional argument. (You could create
% your own custom macro containing the \includegraphics command to make things
% simpler here.)
%\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{mshell}}]{Michael Shell}
% or if you just want to reserve a space for a photo:

\begin{IEEEbiography}{Author}
Biography text here.
\end{IEEEbiography}

% if you will not have a photo at all:
\begin{IEEEbiographynophoto}{Author}
Biography text here.
\end{IEEEbiographynophoto}

% insert where needed to balance the two columns on the last page with
% biographies
%\newpage

\begin{IEEEbiographynophoto}{Author}
Biography text here.
\end{IEEEbiographynophoto}

% You can push biographies down or up by placing
% a \vfill before or after them. The appropriate
% use of \vfill depends on what kind of text is
% on the last page and whether or not the columns
% are being equalized.

%\vfill

% Can be used to pull up biographies so that the bottom of the last one
% is flush with the other column.
%\enlargethispage{-5in}

\end{document}


